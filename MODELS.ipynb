{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d54ce32b-0d8e-4f6b-9024-38a436e6cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Store.csv\", parse_dates=[\"Order Date\", \"Ship Date\"])\n",
    "\n",
    "# Feature Engineering\n",
    "df['Year'] = df['Order Date'].dt.year\n",
    "df['Month'] = df['Order Date'].dt.month.astype(str)       # Treat as categorical\n",
    "df['DayOfWeek'] = df['Order Date'].dt.dayofweek.astype(str)\n",
    "df['Quantity'] = df['Quantity'].astype(str)               # Convert to categorical\n",
    "df['Sales_Discount'] = df['Sales'] * df['Discount']       # Interaction term\n",
    "\n",
    "# Define features and target\n",
    "categorical_features = ['Region', 'Ship Mode', 'Segment', 'Category',\n",
    "                        'Sub-Category', 'Month', 'DayOfWeek', 'Quantity']\n",
    "numerical_features = ['Sales', 'Discount', 'Year', 'Sales_Discount']\n",
    "target = 'Profit'\n",
    "\n",
    "# Full feature matrix and target vector\n",
    "X = df[categorical_features + numerical_features]\n",
    "y = df[target]\n",
    "\n",
    "# One-Hot Encoding\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c16128-af3e-4e72-9b6a-40361978a57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c85f4a6cdb4ac79b96520650ba481b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 693\n",
      "[LightGBM] [Info] Number of data points in the train set: 7995, number of used features: 59\n",
      "[LightGBM] [Info] Start training from score 30.697456\n",
      "                                    Adjusted R-Squared  \\\n",
      "Model                                                    \n",
      "XGBRegressor                                      0.74   \n",
      "HistGradientBoostingRegressor                     0.58   \n",
      "ElasticNetCV                                      0.54   \n",
      "ElasticNet                                        0.52   \n",
      "LinearSVR                                         0.52   \n",
      "KNeighborsRegressor                               0.48   \n",
      "LGBMRegressor                                     0.48   \n",
      "HuberRegressor                                    0.47   \n",
      "TweedieRegressor                                  0.39   \n",
      "MLPRegressor                                      0.38   \n",
      "SGDRegressor                                      0.37   \n",
      "Lasso                                             0.33   \n",
      "LassoLars                                         0.33   \n",
      "BayesianRidge                                     0.33   \n",
      "LarsCV                                            0.33   \n",
      "LassoCV                                           0.33   \n",
      "LassoLarsCV                                       0.33   \n",
      "Ridge                                             0.33   \n",
      "LassoLarsIC                                       0.33   \n",
      "RidgeCV                                           0.33   \n",
      "TransformedTargetRegressor                        0.33   \n",
      "LinearRegression                                  0.33   \n",
      "Lars                                              0.33   \n",
      "KernelRidge                                       0.31   \n",
      "PassiveAggressiveRegressor                        0.29   \n",
      "OrthogonalMatchingPursuit                         0.28   \n",
      "OrthogonalMatchingPursuitCV                       0.28   \n",
      "GradientBoostingRegressor                         0.28   \n",
      "ExtraTreesRegressor                               0.20   \n",
      "BaggingRegressor                                  0.14   \n",
      "RandomForestRegressor                             0.03   \n",
      "NuSVR                                            -0.01   \n",
      "SVR                                              -0.01   \n",
      "DummyRegressor                                   -0.03   \n",
      "GaussianProcessRegressor                         -0.04   \n",
      "AdaBoostRegressor                                -0.14   \n",
      "ExtraTreeRegressor                               -0.53   \n",
      "DecisionTreeRegressor                            -0.67   \n",
      "RANSACRegressor               -84488131812750458880.00   \n",
      "\n",
      "                                             R-Squared             RMSE  \\\n",
      "Model                                                                     \n",
      "XGBRegressor                                      0.74           111.59   \n",
      "HistGradientBoostingRegressor                     0.59           140.75   \n",
      "ElasticNetCV                                      0.55           147.52   \n",
      "ElasticNet                                        0.53           150.73   \n",
      "LinearSVR                                         0.53           150.87   \n",
      "KNeighborsRegressor                               0.50           155.81   \n",
      "LGBMRegressor                                     0.49           156.87   \n",
      "HuberRegressor                                    0.49           157.38   \n",
      "TweedieRegressor                                  0.41           168.80   \n",
      "MLPRegressor                                      0.40           171.21   \n",
      "SGDRegressor                                      0.39           172.51   \n",
      "Lasso                                             0.35           177.46   \n",
      "LassoLars                                         0.35           177.46   \n",
      "BayesianRidge                                     0.35           177.64   \n",
      "LarsCV                                            0.35           177.77   \n",
      "LassoCV                                           0.35           177.94   \n",
      "LassoLarsCV                                       0.35           177.94   \n",
      "Ridge                                             0.35           177.96   \n",
      "LassoLarsIC                                       0.35           177.98   \n",
      "RidgeCV                                           0.35           178.00   \n",
      "TransformedTargetRegressor                        0.35           178.00   \n",
      "LinearRegression                                  0.35           178.00   \n",
      "Lars                                              0.35           178.05   \n",
      "KernelRidge                                       0.33           180.57   \n",
      "PassiveAggressiveRegressor                        0.31           182.99   \n",
      "OrthogonalMatchingPursuit                         0.30           184.36   \n",
      "OrthogonalMatchingPursuitCV                       0.30           184.36   \n",
      "GradientBoostingRegressor                         0.30           184.46   \n",
      "ExtraTreesRegressor                               0.23           193.81   \n",
      "BaggingRegressor                                  0.17           200.60   \n",
      "RandomForestRegressor                             0.06           213.86   \n",
      "NuSVR                                             0.02           217.73   \n",
      "SVR                                               0.02           217.94   \n",
      "DummyRegressor                                   -0.00           220.43   \n",
      "GaussianProcessRegressor                         -0.01           221.06   \n",
      "AdaBoostRegressor                                -0.11           231.70   \n",
      "ExtraTreeRegressor                               -0.48           267.89   \n",
      "DecisionTreeRegressor                            -0.62           280.45   \n",
      "RANSACRegressor               -81950950677232435200.00 1993339446761.89   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "XGBRegressor                         0.21  \n",
      "HistGradientBoostingRegressor        1.03  \n",
      "ElasticNetCV                         0.11  \n",
      "ElasticNet                           0.02  \n",
      "LinearSVR                            0.12  \n",
      "KNeighborsRegressor                  0.12  \n",
      "LGBMRegressor                        0.14  \n",
      "HuberRegressor                       0.12  \n",
      "TweedieRegressor                     0.03  \n",
      "MLPRegressor                         5.63  \n",
      "SGDRegressor                         0.03  \n",
      "Lasso                                0.02  \n",
      "LassoLars                            0.02  \n",
      "BayesianRidge                        0.09  \n",
      "LarsCV                               0.09  \n",
      "LassoCV                              0.11  \n",
      "LassoLarsCV                          0.08  \n",
      "Ridge                                0.02  \n",
      "LassoLarsIC                          0.09  \n",
      "RidgeCV                              0.09  \n",
      "TransformedTargetRegressor           0.07  \n",
      "LinearRegression                     0.08  \n",
      "Lars                                 0.04  \n",
      "KernelRidge                          4.09  \n",
      "PassiveAggressiveRegressor           0.03  \n",
      "OrthogonalMatchingPursuit            0.02  \n",
      "OrthogonalMatchingPursuitCV          0.05  \n",
      "GradientBoostingRegressor            1.03  \n",
      "ExtraTreesRegressor                  5.12  \n",
      "BaggingRegressor                     0.53  \n",
      "RandomForestRegressor                5.11  \n",
      "NuSVR                                3.25  \n",
      "SVR                                  5.73  \n",
      "DummyRegressor                       0.01  \n",
      "GaussianProcessRegressor            11.06  \n",
      "AdaBoostRegressor                    0.50  \n",
      "ExtraTreeRegressor                   0.07  \n",
      "DecisionTreeRegressor                0.09  \n",
      "RANSACRegressor                      0.26  \n"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Transform data\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Convert to DataFrame (force dense array)\n",
    "X_df = pd.DataFrame(X_processed.toarray())\n",
    "\n",
    "# Split\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Run LazyPredict\n",
    "lazy = LazyRegressor(verbose=0, ignore_warnings=True)\n",
    "models, predictions = lazy.fit(X_train_p, X_test_p, y_train_p, y_test_p)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3309078f-4ccf-43c1-b859-c1dd522ee4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regressor\n",
      "R² Score: 0.7432\n",
      "RMSE: 111.59\n",
      "MAE: 23.57\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Encode features with preprocessor → dense array\n",
    "X_encoded = preprocessor.fit_transform(X).toarray()\n",
    "\n",
    "# Train-test split\n",
    "X_train_enc, X_test_enc, y_train_enc, y_test_enc = train_test_split(\n",
    "    X_encoded, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# XGBoost model (default settings)\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "xgb.fit(X_train_enc, y_train_enc)\n",
    "y_pred = xgb.predict(X_test_enc)\n",
    "\n",
    "# Evaluation\n",
    "print(\"XGBoost Regressor\")\n",
    "print(f\"R² Score: {r2_score(y_test_enc, y_pred):.4f}\")\n",
    "print(f\"RMSE: {mean_squared_error(y_test_enc, y_pred, squared=False):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test_enc, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c23243f3-5693-48a8-9202-48ed179adb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "R² Score: 0.3465\n",
      "RMSE: 178.01\n",
      "MAE: 43.26\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Fit\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_enc, y_train_enc)\n",
    "\n",
    "# Predict\n",
    "y_pred_lr = lr.predict(X_test_enc)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Linear Regression\")\n",
    "print(f\"R² Score: {r2_score(y_test_enc, y_pred_lr):.4f}\")\n",
    "print(f\"RMSE: {mean_squared_error(y_test_enc, y_pred_lr, squared=False):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test_enc, y_pred_lr):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c16a12b-1488-468e-87c6-27f6a7907072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor\n",
      "R² Score: -0.0913\n",
      "RMSE: 230.02\n",
      "MAE: 49.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth=5, min_samples_leaf=10, random_state=42)\n",
    "dt.fit(X_train_enc, y_train_enc)\n",
    "y_pred_dt = dt.predict(X_test_enc)\n",
    "\n",
    "print(\"Decision Tree Regressor\")\n",
    "print(f\"R² Score: {r2_score(y_test_enc, y_pred_dt):.4f}\")\n",
    "print(f\"RMSE: {mean_squared_error(y_test_enc, y_pred_dt, squared=False):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test_enc, y_pred_dt):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06676b6e-0136-4341-9335-462d76614245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor\n",
      "R²: 0.0876\n",
      "RMSE: 210.33\n",
      "MAE: 32.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, max_depth=8, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Random Forest Regressor\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"RMSE: {mean_squared_error(y_test, y_pred_rf, squared=False):.2f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_rf):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b633797-a6e3-42ec-9180-e9d8cde9f9da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
